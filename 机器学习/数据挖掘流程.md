[TOC]

## 数据挖掘流程

### 数据探索分析

#### 统计基本信息

单个特征的最大最小值、均值、分位数、缺失程度等。使用DataFrame.describe()。

单个特征的分布可视化，不同类别下特征的分布可视化，可以直观地看出该特征对于类别的区分程度。

多个特征之间相关性分析，可视化相关性矩阵。

#### 其他探索

比赛中往往给定好训练集和测试集，可以对单个特征在训练集和测试集中的分布进行可视化，或者统计单个特征在训练集和测试集中唯一值的数量，目的是发现训练集和测试集数据分布的差异及联系，找出可能存在的规律。如kaggle比赛《Santander Customer Transaction Prediction》中取胜关键在于统计单个特征在训练集和测试集中唯一值的数量，发现其测试集中部分样本为采样得到，并用于指导特征工程。

又如在kaggle比赛《Santander Value Prediction Challenge》中，通过对各个特征的探索分析，发现某几列特征之间是通过时间偏移生成的，从而将问题转化为时间序列问题。

### 数据预处理

数据预处理部分主要是对异常值和缺失值的处理，以及数据变换。

#### 异常值

检测、判断方法：

l 3σ原则和四分位数截断（箱形图法）：作用于单个特征。服从正太分布的数据特征，μ±3σ区域应该包含99.7%的数据，所以可以认为这个区间之外的数据为outliers。类似的，四分位数截断是由25%分位数和75%分位数定义。

l 基于距离等度量。

l 其他情况如在数据探索时提到的，比赛数据集中可以会存在一些官方人为生成的数据或采样数据。

具体的处理手段：

l 根据异常点的数量和影响，考虑是否将该条记录删除，信息损失多

l 若对数据做了log-scale 对数变换后消除了异常值，则此方法生效，且不损失信息

l 平均值或中位数替代异常点，简单高效，信息的损失较少

l 在训练树模型时，树模型对离群点的鲁棒性较高，无信息损失，不影响模型训练效果

#### 缺失值

l 删除变量：如果这个变量的缺失率很高，可以丢掉。

l 用均值/中位数/众数填补，或者对不同类别groupby之后用均值/中位数/众数填补。一般只有在数据波动不是很大，并且该变量对目标变量的影响不大的情况才有很好的效果。

l 插值法填充：包括随机插值，多重差补法，热平台插补，拉格朗日插值，牛顿插值等

l 模型填充：使用回归、贝叶斯、随机森林、决策树等模型对缺失数据进行预测。

l 哑变量填充：若变量是离散型，且不同值较少，可转换成哑变量，例如性别SEX变量，存在male,fameal,NA三个不同的值，可将该列转换成 IS_SEX_MALE, IS_SEX_FEMALE, IS_SEX_NA。若某个变量存在十几个不同的值，可根据每个值的频数，将频数较小的值归为一类'other'，降低维度。此做法可最大化保留变量的信息。

l lightGBM和XGBoost可以直接处理缺失值（当做数据的一部分进行训练），所以可以不做额外处理。

#### 数据变换

l 规范化处理：数据中不同特征的量纲可能不一致，数值间的差别可能很大，不进行处理可能会影响到数据分析的结果，因此，需要对数据按照一定比例进行缩放，使之落在一个特定的区域，便于进行综合分析。特别是基于距离的挖掘方法，聚类，KNN，SVM一定要做规范化处理。最大 - 最小规范化：将数据映射到[0,1]区间；Z-Score标准化：处理后的数据均值为0，方差为1；Log变换：在时间序列数据中，对于数据量级相差较大的变量，通常做Log函数的变换。

l 离散化处理：数据离散化是指将连续的数据进行分段，使其变为一段段离散化的区间。分段的原则有基于等距离、等频率或优化的方法。数据离散化的原因主要有以下几点：有效的离散化能减小算法的时间和空间开销，提高系统对样本的分类聚类能力和抗噪声能力。可以有效的克服数据中隐藏的缺陷，使模型结果更加稳定。

类别型变量编码。如label encoding，one-hot encoding，target encoding，平均数编码、实体嵌入等。